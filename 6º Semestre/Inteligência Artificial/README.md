##### Rio, 18/08/2017
Apresentação da matéria e Trabalho passado para casa.

***

##### Rio, 25/08/2017

Inteligência artificial consiste em fazer com que os computadores passaem a fazer coisas que os humanos ainda fazem melhor.

Os fundamentos de IA iniciou como uma Filosofia no ano 423 AC, posteriormente passando pro âmbito da Matemática no ano 800 AC, Psicologia em 1879 DC e por fim Linguística em 1957 DC.

No início houve uma grande indecisão pela abordagem lógica baseada em conhecimento, já em 1980 os sistemas especialistas haviam dominado a IA. Estatísticas estava fora de uso de reconecimento de padrões de recuperçaão de informações.

Entre 1969 a 1979 tomaram uma verdadeira dose de realidade e IA descobre a complexidade computacional. 

Entre 1980 e 1988 a IA torna parte da indústria com o retorno das Redes Neurais e a nova IA em 1986 através de um algorítmo de aprendizagem de retro programação foi "reinventado".

**Técnicas utilizadas em IA:**
- Resolução de problemas
- Métodos de busca
- Representação de conhecimento
- Sistemas especialistas (RBL e RBC)
- Agentes
- Aprendizagem de máquinas
- Lógicas de Fuzzy (Técnica onde os valores são feitas em variáveis linguísticas)
- Algoritmos genéricos (Analise como os seres vivos sofrem suas mutações durante a evolução)
- Conexionismo (Trabalha na conexão do sistema nervoso dos seres vivos)
- PLN (Programação de linguagem natural, fazer programa para serem FALADOS)
- Robótica
- Mineração de dados
 

**Agentes:**
> Entidade computacional que funciona de fomra contínua e autônoma em um ambiente restrito. Pode coexistir com outros agentes com características comuns ou não.


**As técnicas de IA são métodos que exploram o conhecimento e devem ser representadas de maneiras:**
- Conhecimento capture a generalização
- Possam ser compreendidas pelas pessoas que forneçam
- Possam ser facilmente modificadas para correção de erros
- Possam ser utilizadas em uma variedade de situações


**Características de Sistemas de IA:**
- Sistemas de IA não fornecem resultados exatos
- Sempre que houver soluções fechadas a IA não é competitiva
- Havendo incerteza, ambiguidade ou preferência humana a IA é imbatível
- IA mexe com o imaginário e permite **cobrar mais caro**


### Aprendizagem de Máquinas

Começou a florescer nos anos 90, focando em métodos e modelos emprestados da estatísticas e da teoria da probabilidade, se beneficiou do crescente número de informações digitalizadas disponível.

Com a aprendizagem de máquinas e a mineração de dados possibilitam fazer uso dos mesmos métodos e se sobrepôem, focando em permitir previsões, descobrir propriedades (previamente) _desconhecidas_ nos dados.
> - Aprendizado -> Prever
> - Mineração -> Descobrir

**Tecnologias em aprendizagens:**
- Árvore de decisão
- Naive Bayes
- Regressão de Logísticas
- Redes Neurais
- Etc

**Análise de Agrupamentos:**
Dada uma coleção de objetos a fim de formar grupo com base familiar, usando a ciência "baseada em descoberta" encontra padrões inesperados em dados, gerando aprendizagem não supervisionada podendo causar um problema _mal definido_.

Por ser mal definido precisa ser interpretado (esta incerteza) com novas variáveis, informações ou atributos de um novo "padrão" possível.

**Redes Naurais:**
Uma rede naural artificial petence em um modelo matemático que tende a "imitar" uma célula de neurônio de seres vivos. Onde a informação é generada através de particulas de carga elétrica e modificam o estado elétrico da célula que já se econtrava no local através de uma descarga elétrica. (Zeros e Uns)



**Deep Learning:**
É a área de IA que vem desde 2006, sendo acelerado após 2010. Tem grande variação das Redes Neurais na questão de profundidade das camadas ocultas. Onde as redes neurais tem poucas camadas ocultas a deep learning trabalha com muitas, tendo mais informações a serem passadas e aprendidas ao passar em cada camada.



***

##### Rio, 01/09/2017

### Big Data Analytics

Os **3V**:

**Volume:** Troca de e-mail, transações bancárias, interações em redes sociais, registro de chamadas e tráfego de dados em linhas telefônicas e principalmente logs.

**Velocidade:** Capacidade de analáse em tempo real.

**Variedade:** Dados estruturado e não estruturado.

Hoje em dia já existe muitas ferramentas de auxilio para criação de ferramentas de mineração em BI.

**Fatos dfe Big data:**
- Menos de 1% de dados do mundo ão analisados.
- Mais dados dforam criados nos último 5 anos
- Em agosto de 2015, mais de  bilhão de pessoas usaram o Facebook em um único dia.
- Em 2017, a expectativa é de 2 bilhoes de usários de acessa ao Facebook.

 
O Termo foi tão usado comercialmente que perdeu o sentido, acaba sendo como sexo na adolescencia onde todos falam sobre, onde na verdade ninguém sabe exatamente como fazer, todos pensam que estão fazendo e por isso afirmam que fazem.


**Conhecimento em:**
- Estatística
- Computação
- Negócio
- Projetos

**Titulação**
- Ph.D
- MSc

**Personalidade:**
- Pensamento orientado a negócias
- Saber fazer as perguntas certas

**Pesquisar:**
- Hadoop (Hive com Rui) [Faz processamento no HD]
- Cloudera
- MapReduce
- AWS EMR (Elastic MapReduce)
- Apache Spark [Faz o processamento na memória]



Hadoop é um softare de código aberto devesenvolvido em Java para computação distribuída, é escalável horizontalmente e tolerante a falhas.

O grande ganho com esta plataforma é a redução de compplexidade para computação distribuída, pois todo o processo ocorre através da integração software e maquina.

Um ambiente de processamento em parelo, se faz necessário especificar praticamente tudo, desde quem é o processadr que envia, para onde envia, como envia. Do lado que recebe, qual o processador que recebe, o que recebe, como recebe, etc.

Hadoop gerencia tudo isto, de forma única. Basta utilizar o paradigma de programação **Map Reduce**, que todo o processamento é distribuído de forma implícita, uma vez que o dado esteja contido no **HDFS**.

A técnica comeceu sendo:
- HDFS era o hardware
- Map Reduce era o software




***

##### Rio, 08/09/2017

### Analytics em Tudo

MeetUp
> Plataforma de prover possibilidade de de agrupar pessoas que tem o mesmo interesse em um determinado assunto.

Dados aberto
> Dados aberto é um dado que pode ser livremente utilizado, reutilizado e redistribuído por qualquer um (Manual dos Dados Abertos: governo)

Características de um dados aberto:
- Disponibilidade de Acesso
- Reuso e redistribuição
- particição universal
- Completos
- Primários
- Atuais
- Acessíveis 
- Compreensíveis por máquinas
- Não proprietário
- Livres de licenças

**Estratégias:**
Disponibilizar um conjunto de dados brutos, com máximo de detalhamento possível, permite que a sociedade use os dados de maneira mais dinâmica, por exemplo, convertendo em outros formatos ou mesmo integrando com outros recursos; sendo disponibilizados por API ou para baixar.
















































